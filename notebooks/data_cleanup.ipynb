{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Airbnb Price Prediction - Data Cleanup\n",
    "\n",
    "Use dataset published by Kaggle - https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data - to train a simple deep learning model to predict prices for Airbnb properties.\n",
    "\n",
    "\n",
    "This notebook contains the data cleanup steps:\n",
    "- load data from the input CSV or dataframe saved in data preparation step\n",
    "- fix missing values\n",
    "- clean up anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common imports and variables\n",
    "Imports and variable definitions that are common to the entire notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.22.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (1.25.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (2019.6.16)\n",
      "Requirement already satisfied: xlrd in c:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.2.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.3, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "# common imports\n",
    "import zipfile\n",
    "import time\n",
    "# import datetime, timedelta\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "from dateutil import relativedelta\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import os\n",
    "import math\n",
    "from subprocess import check_output\n",
    "from IPython.display import display\n",
    "import logging\n",
    "import yaml\n",
    "from collections import Counter\n",
    "import re\n",
    "import os\n",
    "import numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(config_file):\n",
    "    ''' open config file with name config_file that contains parameters\n",
    "    for this module and return Python object\n",
    "\n",
    "    Args:\n",
    "        config_file: filename containing config parameters\n",
    "\n",
    "    Returns:\n",
    "        config: Python dictionary with config parms from config file - dictionary\n",
    "\n",
    "\n",
    "    '''\n",
    "    current_path = os.getcwd()\n",
    "    path_to_yaml = os.path.join(current_path, config_file)\n",
    "    print(\"path_to_yaml \" + path_to_yaml)\n",
    "    try:\n",
    "        with open(path_to_yaml, 'r') as c_file:\n",
    "            config = yaml.safe_load(c_file)\n",
    "        return config\n",
    "    except Exception as error:\n",
    "        print('Error reading the config file ' + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config_values(config):\n",
    "    for val in config:\n",
    "        print(\"config value \",val,\" \",str(config[val]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataframe\n",
    "- load pickled dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path():\n",
    "    ''' get the path for data files\n",
    "\n",
    "    Returns:\n",
    "        path: path for data directory\n",
    "\n",
    "    '''\n",
    "    rawpath = os.getcwd()\n",
    "    # data is in a directory called \"data\" that is a sibling to the directory\n",
    "    # containing the notebook\n",
    "    path = os.path.abspath(os.path.join(rawpath, '..', 'data'))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_data(path,input_csv,pickled_input_dataframe,save_raw_dataframe,load_from_scratch):\n",
    "    ''' load data into dataframe\n",
    "    Args:\n",
    "        path: path containing input file\n",
    "        input_csv: input file name\n",
    "        pickled_input_dataframe: pickled version of input file\n",
    "\n",
    "    Returns:\n",
    "        path: path for data directory\n",
    "    '''\n",
    "    if load_from_scratch:\n",
    "        unpickled_df = pd.read_csv(os.path.join(path,input_csv)) \n",
    "        if save_raw_dataframe:\n",
    "            file_name = os.path.join(path,pickled_input_dataframe)\n",
    "            print(\"file_name is \",file_name)\n",
    "            unpickled_df.to_pickle(file_name)\n",
    "    else:\n",
    "        unpickled_df = pd.read_pickle(os.path.join(path,pickled_input_dataframe))\n",
    "        logging.debug(\"reloader done\")\n",
    "    return(unpickled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(dataset,columns,defaults):\n",
    "    ''' replace missing values with placeholders by column type\n",
    "    \n",
    "    Args:\n",
    "        dataset: dataframe in which missing values being processed\n",
    "        columns: dictionary of columns with keys that are column types and values that are the column names of that type\n",
    "        defaults: dictionary of replacement values for missing values by column type\n",
    "\n",
    "    Returns:\n",
    "        dataset: dataframe with missing values replaced with default values\n",
    "\n",
    "    '''\n",
    "    logging.debug(\"before mv\")\n",
    "    for column_category in columns:\n",
    "        print(\"column_category is \"+str(column_category))\n",
    "        for col in columns[column_category]:\n",
    "            print(\"filling mising values in col \"+str(col)+\" with default \"+str(defaults[column_category]))\n",
    "            dataset[col].fillna(defaults[column_category],inplace = True)\n",
    "            print(\"in mv Missing values in \",col,\" \",str(dataset[col].isna().sum()))\n",
    "     \n",
    "    return(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_in_list(x, list):\n",
    "    ''' check if a value is in a list\n",
    "    Args:\n",
    "        x: value to check\n",
    "        list: list in which to check for the value\n",
    "\n",
    "    Returns:\n",
    "        retur_val: 1 if value is in not in list, 0 otherwise\n",
    "    '''\n",
    "    if x in list:\n",
    "        return_val = 0\n",
    "    else:\n",
    "        return_val = 1\n",
    "    return(return_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_val(x):\n",
    "    ''' check if a value is in a list\n",
    "    Args:\n",
    "        x: value to check\n",
    "    \n",
    "    Returns:\n",
    "        retur_val: 1 if value is negative, 0 otherwise\n",
    "    '''\n",
    "    if x >= 0:\n",
    "        return_val = 0\n",
    "    else:\n",
    "        return_val = 1\n",
    "    return(return_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_if_not_in_list(x, replace_x, list):\n",
    "    ''' check if a value is in a list\n",
    "    Args:\n",
    "        x: value to check\n",
    "        list: list in which to check for the value\n",
    "\n",
    "    Returns:\n",
    "        retur_val: 1 if value is in not in list, 0 otherwise\n",
    "    '''\n",
    "    if x in list:\n",
    "        return_val = x\n",
    "    else:\n",
    "        return_val = replace_x\n",
    "    return(return_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_if_neg(x, replace_x):\n",
    "    ''' check if a value is negative and replace if so\n",
    "    Args:\n",
    "        x: value to check\n",
    "    \n",
    "    Returns:\n",
    "        retur_val: 1 if value is negative, 0 otherwise\n",
    "    '''\n",
    "    if x >= 0:\n",
    "        return_val = x\n",
    "    else:\n",
    "        return_val = replace_x\n",
    "    return(return_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_if_non_numeric(x, replace_x):\n",
    "    ''' check if a value is non-numeric and replace if so\n",
    "    Args:\n",
    "        x: value to check\n",
    "    \n",
    "    Returns:\n",
    "        retur_val: 1 if value is negative, 0 otherwise\n",
    "    '''\n",
    "    if isinstance(x, numbers.Number):\n",
    "        return_val = x\n",
    "    else:\n",
    "        return_val = replace_x\n",
    "    return(return_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_assessment(df,columns,valid_values,non_neg_continuous):\n",
    "    ''' assess the values in a dataframe\n",
    "    Args:\n",
    "        df: dataframe for assessment\n",
    "        columns: dictionary of column names by category\n",
    "        valid_values: dictionary of valid values for categorical columns with limited number of valid values\n",
    "        non_neg_continuous: list of continuous columns with only non-negative values as valid\n",
    "    '''\n",
    "    for col in list(df):\n",
    "        print(\"Missing values in \",col,\" \",str(df[col].isna().sum()))\n",
    "        print(\"Distinct values in \",col,\" \",str(df[col].nunique()))\n",
    "    # for categorical columns with a limited number of valid values, count the number of invalid values by column\n",
    "    for col in valid_values:\n",
    "        print(\"non-valid values in column \",col,\" \",str(df[col].apply(lambda x:not_in_list(x,valid_values[col])).sum()))\n",
    "    # count non-numeric values in continuous columns\n",
    "    for col in columns['continuous']:\n",
    "        # mask = pd.to_numeric(df['Hours_Worked'], errors='coerce').isna()\n",
    "        mask = pd.to_numeric(df[col], errors='coerce').isna()\n",
    "        print(\"non-numeric values in continuous col \",col,\" \",str(mask.sum()))\n",
    "        # if there are no non-numeric values in the column and it muast have non-negative values, count negative values\n",
    "        if (mask.sum()==0) and (col in non_neg_continuous):\n",
    "            print(\"negative values in colum \",col,\" \",str(df[col].apply(lambda x:neg_val(x)).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_invalid_values(df,columns,valid_values,invalid_value_replacements,non_neg_continuous):\n",
    "    ''' replace invalid with placeholders\n",
    "    Args:\n",
    "        df: dataframe for assessment\n",
    "        columns: dictionary of column names by category\n",
    "        valid_values: dictionary of valid values for categorical columns with limited number of valid values\n",
    "        invalid_value_replacements: dictionary of replacement values by column category\n",
    "        non_neg_continuous: list of continuous columns with only non-negative values as valid\n",
    "    '''\n",
    "    # for categorical columns with a limited number of valid values, count the number of invalid values by column\n",
    "    for col in valid_values:\n",
    "        print(\"non-valid values in column \",col,\" \",str(df[col].apply(lambda x:not_in_list(x,valid_values[col])).sum()))\n",
    "        df[col] = df[col].apply(lambda x:replace_if_not_in_list(x,invalid_value_replacements[col],valid_values[col]))\n",
    "    # count non-numeric values in continuous columns\n",
    "    for col in in non_neg_continuous:\n",
    "        # if there are no non-numeric values in the column and it muast have non-negative values, count negative values\n",
    "        df[col] = df[col].apply(lambda x:replace_if_non_numeric(x,invalid_value_replacements[col]))\n",
    "        if col in non_neg_continuous:\n",
    "            df[col] = df[col].apply(lambda x:replace_if_neg(x,invalid_value_replacements[col])) \n",
    "    return(df)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_of_range(x,max,min):\n",
    "    ''' count whether a value is in a range\n",
    "    Args:\n",
    "        x: value to check in range\n",
    "        max: top of the range to check\n",
    "        min: bottom of the range to check\n",
    "        \n",
    "    Returns:\n",
    "        ret_val: 1 if out of range, 0 otherwise\n",
    "    '''\n",
    "    if x > max or x < min:\n",
    "        return_val = 1\n",
    "    else:\n",
    "        return_val = 0\n",
    "    return(return_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_of_bounding_box(latitude,longitude,bounding_box):\n",
    "    ''' count whether a location is within a bounding box\n",
    "    Args:\n",
    "        latitude: latitude portion of location\n",
    "        longitude: longitude portion of location\n",
    "        bounding_box: dictionary with max and min values to compare the location with\n",
    "        min: bottom of the range to check\n",
    "        \n",
    "    Returns:\n",
    "        ret_val: 1 if out of range, 0 otherwise\n",
    "    '''    \n",
    "    if ((latitude <= bounding_box['max_lat']) and (latitude >= bounding_box['min_lat'])) \\\n",
    "    and ((longitude <= bounding_box['max_long']) and (longitude >= bounding_box['min_long'])):\n",
    "         ret_val = 0\n",
    "    else:\n",
    "         ret_val = 1\n",
    "    return(ret_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_assessment(df,bounding_box):\n",
    "    ''' assess the geo columns in a dataframe by counting how many latitude and longitude values are outside the bounding box\n",
    "    Args:\n",
    "        df: dataframe for assessment\n",
    "        bounding_box: dictionary of maximum and minimum valid latitude and longitude values\n",
    "    ''' \n",
    "    # count the number of entries in the latitude column that are above or below a given amount\n",
    "    # df['col_3'] = df.apply(lambda x: get_sublist(x.col_1, x.col_2), axis=1)\n",
    "    print(\"latitude out of bounds count \",str(df['latitude'].apply(lambda x:out_of_range(x,bounding_box['max_lat'],bounding_box['min_lat'])).sum()))\n",
    "    print(\"longitude out of bounds count \",str(df['longitude'].apply(lambda x:out_of_range(x,bounding_box['max_long'],bounding_box['min_long'])).sum()))\n",
    "    print(\"location out of bounds count \",str(df.apply(lambda x: out_of_bounding_box(x.latitude,x.longitude,bounding_box), axis=1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_time(date_time_value,time_value):\n",
    "    ''' given a datetime replace the time portion '''\n",
    "     \n",
    "    date_time_value = date_time_value.replace(hour=time_value.hour,minute=time_value.minute,second=time_value.minute)\n",
    "    return(date_time_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master cell\n",
    "This cell contains calls to the other functions in this notebook to complete the data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:logging check\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path is  C:\\personal\\manning_liveproject\\end_to_end_deep_learning_live_project\\data\n",
      "path_to_yaml C:\\personal\\manning_liveproject\\end_to_end_deep_learning_live_project\\notebooks\\data_preparation_config.yml\n",
      "past config definition\n",
      "config value  general   {'load_from_scratch': False, 'save_raw_dataframe': False, 'save_transformed_dataframe': False, 'remove_bad_values': True}\n",
      "config value  columns   {'categorical': ['neighbourhood_group', 'neighbourhood', 'room_type'], 'continuous': ['minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'latitude', 'longitude'], 'date': ['last_review'], 'text': ['name', 'host_name'], 'excluded': ['price', 'id']}\n",
      "config value  category_defaults   {'categorical': 'missing', 'continuous': 0.0, 'text': 'missing', 'date': datetime.date(2019, 1, 1), 'excluded': 'missing'}\n",
      "config value  category_invalid_value_replacements   {'categorical': 'bad_categorical', 'continuous': 'bad_continuous', 'text': 'bad_text', 'date': 'bad_date', 'exclude': 'bad_excluded'}\n",
      "config value  non_negative_continuous   ['minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count']\n",
      "config value  valid_values   {'neighbourhood_group': ['Bronx', 'Brooklyn', 'Queens', 'Manhattan', 'Staten Island'], 'room_type': ['Private room', 'Shared room', 'Entire home/apt']}\n",
      "config value  bounding_box   {'max_long': -73.70018092, 'max_lat': 40.91617849, 'min_long': -74.25909008, 'min_lat': 40.47739894}\n",
      "config value  newark_bounding_box   {'max_long': -74.11278706, 'max_lat': 40.67325015, 'min_long': -74.25132408, 'min_lat': 40.78813864}\n",
      "config value  geo_columns   ['latitude', 'longitude']\n",
      "config value  file_names   {'input_csv': 'AB_NYC_2019.csv', 'pickled_input_dataframe': 'AB_NYC_2019_input_aug16_2020.pkl', 'pickled_output_dataframe': 'AB_NYC_2019_output_aug16_2020.pkl'}\n",
      "columns is {'categorical': ['neighbourhood_group', 'neighbourhood', 'room_type'], 'continuous': ['minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'latitude', 'longitude'], 'date': ['last_review'], 'text': ['name', 'host_name'], 'excluded': ['price', 'id']}\n",
      "category_defaults is {'categorical': 'missing', 'continuous': 0.0, 'text': 'missing', 'date': datetime.date(2019, 1, 1), 'excluded': 'missing'}\n",
      "column_category is categorical\n",
      "filling mising values in col neighbourhood_group with default missing\n",
      "in mv Missing values in  neighbourhood_group   0\n",
      "filling mising values in col neighbourhood with default missing\n",
      "in mv Missing values in  neighbourhood   0\n",
      "filling mising values in col room_type with default missing\n",
      "in mv Missing values in  room_type   0\n",
      "column_category is continuous\n",
      "filling mising values in col minimum_nights with default 0.0\n",
      "in mv Missing values in  minimum_nights   0\n",
      "filling mising values in col number_of_reviews with default 0.0\n",
      "in mv Missing values in  number_of_reviews   0\n",
      "filling mising values in col reviews_per_month with default 0.0\n",
      "in mv Missing values in  reviews_per_month   0\n",
      "filling mising values in col calculated_host_listings_count with default 0.0\n",
      "in mv Missing values in  calculated_host_listings_count   0\n",
      "filling mising values in col latitude with default 0.0\n",
      "in mv Missing values in  latitude   0\n",
      "filling mising values in col longitude with default 0.0\n",
      "in mv Missing values in  longitude   0\n",
      "column_category is date\n",
      "filling mising values in col last_review with default 2019-01-01\n",
      "in mv Missing values in  last_review   0\n",
      "column_category is text\n",
      "filling mising values in col name with default missing\n",
      "in mv Missing values in  name   0\n",
      "filling mising values in col host_name with default missing\n",
      "in mv Missing values in  host_name   0\n",
      "column_category is excluded\n",
      "filling mising values in col price with default missing\n",
      "in mv Missing values in  price   0\n",
      "filling mising values in col id with default missing\n",
      "in mv Missing values in  id   0\n",
      "Missing values in  id   0\n",
      "Distinct values in  id   48895\n",
      "Missing values in  name   0\n",
      "Distinct values in  name   47906\n",
      "Missing values in  host_id   0\n",
      "Distinct values in  host_id   37457\n",
      "Missing values in  host_name   0\n",
      "Distinct values in  host_name   11453\n",
      "Missing values in  neighbourhood_group   0\n",
      "Distinct values in  neighbourhood_group   5\n",
      "Missing values in  neighbourhood   0\n",
      "Distinct values in  neighbourhood   221\n",
      "Missing values in  latitude   0\n",
      "Distinct values in  latitude   19048\n",
      "Missing values in  longitude   0\n",
      "Distinct values in  longitude   14718\n",
      "Missing values in  room_type   0\n",
      "Distinct values in  room_type   3\n",
      "Missing values in  price   0\n",
      "Distinct values in  price   674\n",
      "Missing values in  minimum_nights   0\n",
      "Distinct values in  minimum_nights   109\n",
      "Missing values in  number_of_reviews   0\n",
      "Distinct values in  number_of_reviews   394\n",
      "Missing values in  last_review   0\n",
      "Distinct values in  last_review   1765\n",
      "Missing values in  reviews_per_month   0\n",
      "Distinct values in  reviews_per_month   938\n",
      "Missing values in  calculated_host_listings_count   0\n",
      "Distinct values in  calculated_host_listings_count   47\n",
      "Missing values in  availability_365   0\n",
      "Distinct values in  availability_365   366\n",
      "non-valid values in column  neighbourhood_group   0\n",
      "non-valid values in column  room_type   0\n",
      "non-numeric values in continuous col  minimum_nights   0\n",
      "negative values in colum  minimum_nights   0\n",
      "non-numeric values in continuous col  number_of_reviews   0\n",
      "negative values in colum  number_of_reviews   0\n",
      "non-numeric values in continuous col  reviews_per_month   0\n",
      "negative values in colum  reviews_per_month   0\n",
      "non-numeric values in continuous col  calculated_host_listings_count   0\n",
      "negative values in colum  calculated_host_listings_count   0\n",
      "non-numeric values in continuous col  latitude   0\n",
      "non-numeric values in continuous col  longitude   0\n",
      "non-valid values in column  neighbourhood_group   0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'neighbourhood_group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-2c359a617372>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mbasic_assessment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'columns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valid_values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'non_negative_continuous'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# df = replace_invalid_values(df,columns,valid_values,invalid_value_replacements,non_neg_continuous)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreplace_invalid_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'columns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valid_values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category_invalid_value_replacements'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'non_negative_continuous'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mgeo_assessment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bounding_box'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'general'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'save_transformed_dataframe'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-152-494d4fe23103>\u001b[0m in \u001b[0;36mreplace_invalid_values\u001b[1;34m(df, columns, valid_values, invalid_value_replacements, non_neg_continuous)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"non-valid values in column \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnot_in_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mreplace_if_not_in_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minvalid_value_replacements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;31m# count non-numeric values in continuous columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'continuous'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanm\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4040\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4042\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4044\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-152-494d4fe23103>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"non-valid values in column \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnot_in_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mreplace_if_not_in_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minvalid_value_replacements\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;31m# count non-numeric values in continuous columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'continuous'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'neighbourhood_group'"
     ]
    }
   ],
   "source": [
    "# master cell to call the other functions\n",
    "# get the path for data files\n",
    "path = get_path()\n",
    "print(\"path is \",path)\n",
    "config = get_config('data_preparation_config.yml')\n",
    "print(\"past config definition\")\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "logging.warning(\"logging check\")\n",
    "print_config_values(config)\n",
    "# load dataframe\n",
    "df = ingest_data(path,config['file_names']['input_csv'],config['file_names']['pickled_input_dataframe'],config['general']['save_raw_dataframe'],config['general']['load_from_scratch'])\n",
    "print(\"columns is \"+str(config['columns']))\n",
    "print(\"category_defaults is \"+str(config['category_defaults']))\n",
    "# fill missing values according to the defaults per column\n",
    "df = fill_missing(df,config['columns'],config['category_defaults'])\n",
    "# get assessment results after filling missing values\n",
    "basic_assessment(df,config['columns'],config['valid_values'],config['non_negative_continuous'])\n",
    "# df = replace_invalid_values(df,columns,valid_values,invalid_value_replacements,non_neg_continuous)\n",
    "df = replace_invalid_values(df,config['columns'],config['valid_values'],config['category_invalid_value_replacements'],config['non_negative_continuous'])\n",
    "geo_assessment(df,config['bounding_box'])\n",
    "if config['general']['save_transformed_dataframe']:\n",
    "    print(\"path is \",path)\n",
    "    file_name = os.path.join(path,config['file_names']['pickled_output_dataframe'])\n",
    "    print(\"file_name is \",file_name)\n",
    "    df.to_pickle(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
